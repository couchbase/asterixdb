[[tokenizing-functions]]
== Tokenizing Functions

[[word_tokens]]
=== word_tokens

* Syntax:
+
-------------------
word_tokens(string)
-------------------
* Returns an array of word tokens of `string` using non_alphanumeric
characters as delimiters.
* Arguments:
** `string` : a `string` that will be tokenized.
* Return Value:
** an `array` of `string` word tokens,
** `missing` if the argument is a `missing` value,
** `null` if the argument is a `null` value,
** any other non-string input value will cause a type error.
* Example:
+
------------------------------------------
word_tokens("I like the phone, awesome!");
------------------------------------------
* The expected result is:
+
------------------------------------------
[ "i", "like", "the", "phone", "awesome" ]
------------------------------------------

